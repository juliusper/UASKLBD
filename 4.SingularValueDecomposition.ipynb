--2023-01-05 11:01:49--  https://github.com/nzhinusoftcm/review-on-collaborative-filtering/raw/master/recsys.zip
Resolving github.com (github.com)... 140.82.112.3
Connecting to github.com (github.com)|140.82.112.3|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://raw.githubusercontent.com/nzhinusoftcm/review-on-collaborative-filtering/master/recsys.zip [following]
--2023-01-05 11:01:50--  https://raw.githubusercontent.com/nzhinusoftcm/review-on-collaborative-filtering/master/recsys.zip
Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...
Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 15312323 (15M) [application/zip]
Saving to: ‘recsys.zip’

recsys.zip          100%[===================>]  14.60M  --.-KB/s    in 0.1s    

2023-01-05 11:01:50 (118 MB/s) - ‘recsys.zip’ saved [15312323/15312323]

Archive:  recsys.zip
   creating: recsys/
  inflating: recsys/datasets.py      
  inflating: recsys/preprocessing.py  
  inflating: recsys/utils.py         
  inflating: recsys/requirements.txt  
   creating: recsys/.vscode/
  inflating: recsys/.vscode/settings.json  
   creating: recsys/__pycache__/
  inflating: recsys/__pycache__/datasets.cpython-36.pyc  
  inflating: recsys/__pycache__/datasets.cpython-37.pyc  
  inflating: recsys/__pycache__/utils.cpython-36.pyc  
  inflating: recsys/__pycache__/preprocessing.cpython-37.pyc  
  inflating: recsys/__pycache__/datasets.cpython-38.pyc  
  inflating: recsys/__pycache__/preprocessing.cpython-36.pyc  
  inflating: recsys/__pycache__/preprocessing.cpython-38.pyc  
   creating: recsys/memories/
  inflating: recsys/memories/ItemToItem.py  
  inflating: recsys/memories/UserToUser.py  
   creating: recsys/memories/__pycache__/
  inflating: recsys/memories/__pycache__/UserToUser.cpython-36.pyc  
  inflating: recsys/memories/__pycache__/UserToUser.cpython-37.pyc  
  inflating: recsys/memories/__pycache__/ItemToItem.cpython-37.pyc  
  inflating: recsys/memories/__pycache__/user2user.cpython-36.pyc  
  inflating: recsys/memories/__pycache__/ItemToItem.cpython-36.pyc  
   creating: recsys/models/
  inflating: recsys/models/SVD.py    
  inflating: recsys/models/MatrixFactorization.py  
  inflating: recsys/models/ExplainableMF.py  
  inflating: recsys/models/NonnegativeMF.py  
   creating: recsys/models/__pycache__/
  inflating: recsys/models/__pycache__/SVD.cpython-36.pyc  
  inflating: recsys/models/__pycache__/MatrixFactorization.cpython-37.pyc  
  inflating: recsys/models/__pycache__/ExplainableMF.cpython-36.pyc  
  inflating: recsys/models/__pycache__/ExplainableMF.cpython-37.pyc  
  inflating: recsys/models/__pycache__/MatrixFactorization.cpython-36.pyc  
   creating: recsys/metrics/
  inflating: recsys/metrics/EvaluationMetrics.py  
   creating: recsys/img/
  inflating: recsys/img/MF-and-NNMF.png  
  inflating: recsys/img/svd.png      
  inflating: recsys/img/MF.png       
   creating: recsys/predictions/
   creating: recsys/predictions/item2item/
   creating: recsys/weights/
   creating: recsys/weights/item2item/
   creating: recsys/weights/item2item/ml1m/
  inflating: recsys/weights/item2item/ml1m/similarities.npy  
  inflating: recsys/weights/item2item/ml1m/neighbors.npy  
   creating: recsys/weights/item2item/ml100k/
  inflating: recsys/weights/item2item/ml100k/similarities.npy  
  inflating: recsys/weights/item2item/ml100k/neighbors.npy  
Import requirements
matplotlib==3.2.2
numpy==1.19.2
pandas==1.0.5
python==3.7
scikit-learn==0.24.1
scikit-surprise==1.1.1
scipy==1.6.2
[2]
0s
from recsys.datasets import mlLastedSmall, ml100k, ml1m
from sklearn.preprocessing import LabelEncoder
from scipy.sparse import csr_matrix

import pandas as pd
import numpy as np
import os

Loading movielen ratings
[ ]
0s
ratings, movies = mlLastedSmall.load()
Let's see how our rating matrix looks like

[ ]
0s
pd.crosstab(ratings.userid, ratings.itemid, ratings.rating, aggfunc=sum)
We can observe that our rating matrix has many of unobserved value. However, as we described earlier, the SVD algorithm requires that all inputs in the matrix must be defined. Let's initialize the unobserved ratings with item's average that led to better performances compared to the user's average or even a null initialization (Sarwar et al. (2000)).

We can go further and subtrat from each rating the corresponding user mean to normalize the data. This helps to improve the accuracy of the model.

[ ]
0s
# get user's mean rating
umean = ratings.groupby(by='userid')['rating'].mean()
[ ]
0s
def rating_matrix(ratings):
    """
    1. Fill NaN values with item's average ratings
    2. Normalize ratings by subtracting user's mean ratings
    
    :param ratings : DataFrame of ratings data
    :return
        - R : Numpy array of normalized ratings
        - df : DataFrame of normalized ratings
    """
    
    # fill missing values with item's average ratings
    df = pd.crosstab(ratings.userid, ratings.itemid, ratings.rating, aggfunc=sum)
    df = df.fillna(df.mean(axis=0))
    
    # subtract user's mean ratings to normalize data
    df = df.subtract(umean, axis=0)
    
    # convert our dataframe to numpy array
    R = df.to_numpy()
    
    return R, df

# generate rating matrix by calling function rating_matrix
R, df = rating_matrix(ratings)
R is our final rating matrix. This is how the final rating matrix looks like

[ ]
0s
df
Ids encoding
Let's encode users and items ids such that their values range from 0 to 909 (for users) and from 0 to 9723 (for items)

[ ]
0s
users = sorted(ratings['userid'].unique())
items = sorted(ratings['itemid'].unique())

# create our id encoders
uencoder = LabelEncoder()
iencoder = LabelEncoder()

# fit our label encoder
uencoder.fit(users)
iencoder.fit(items)
SVD Algorithm
Now that our rating data has been normalize and that missing values has been filled, we can apply the SVD algorithm. Several libraries may be useful such as numpy, scipy, sklearn, ... Let's try it with numpy.

In our SVD class we provide the following function :

fit() : compute the svd of the rating matrix and save the resultant matrices P, S and Qh (Q transpose) as attributs of the SVD class.
predict(): use matrices P, S and Qh to make ratin prediction for a given u user on an item i. Computations are made over encoded values of userid and itemid. The predicted value is the dot product between uth row of P.S−−√ and the ith column of S−−√.Qh. Note that since we normalized rating before applying SVD, the predicted value will also be normalize. So, to get the final predicted rating, we have to add to the predicted value the mean rating of user u.
recommend(): use matrices P, S and Qh to make recommendations to a given user. The recommended items are those that where not rated by the user and received a high score according to the svd model.
[ ]
0s
class SVD:
    
    def __init__(self, umeam):
        """
        :param
            - umean : mean ratings of users
        """
        self.umean = umean.to_numpy()
        
        # init svd resultant matrices
        self.P = np.array([])
        self.S = np.array([])
        self.Qh = np.array([])
        
        # init users and items latent factors
        self.u_factors = np.array([])
        self.i_factors = np.array([])
    
    def fit(self, R):
        """
        Fit the SVD model with rating matrix R
        """
        P, s, Qh = np.linalg.svd(R, full_matrices=False)
        
        self.P = P
        self.S = np.diag(s)
        self.Qh = Qh
        
        # latent factors of users (u_factors) and items (i_factors)
        self.u_factors = np.dot(self.P, np.sqrt(self.S))
        self.i_factors = np.dot(np.sqrt(self.S), self.Qh)
    
    def predict(self, userid, itemid):
        """
        Make rating prediction for a given user on an item
        
        :param
            - userid : user's id
            - itemid : item's id
            
        :return
            - r_hat : predicted rating
        """
        # encode user and item ids
        u = uencoder.transform([userid])[0]
        i = iencoder.transform([itemid])[0]
        
        # the predicted rating is the dot product between the uth row 
        # of u_factors and the ith column of i_factors
        r_hat = np.dot(self.u_factors[u,:], self.i_factors[:,i])
        
        # add the mean rating of user u to the predicted value
        r_hat += self.umean[u]
        
        return r_hat
        
    
    def recommend(self, userid):
        """
        :param
            - userid : user's id
        """
        # encode user
        u = uencoder.transform([userid])[0]
        
        # the dot product between the uth row of u_factors and i_factors returns
        # the predicted value for user u on all items        
        predictions = np.dot(self.u_factors[u,:], self.i_factors) + self.umean[u]
        
        # sort item ids in decreasing order of predictions
        top_idx = np.flip(np.argsort(predictions))

        # decode indices to get their corresponding itemids
        top_items = iencoder.inverse_transform(top_idx)
        
        # sorted predictions
        preds = predictions[top_idx]
        
        return top_items, preds
        
Now let's create our SVD model and provide to it user's mean rating; Fit the model with the normalized rating matrix R.

[ ]
0s
# create our svd model
svd = SVD(umean)

# fit our model with normalized ratings
svd.fit(R)
Rating prediction
Our model has been fitted. OK ...

Let's make some predictions for users using function predict of our SVD class. Here are some truth ratings

[ ]
0s
ratings.head(10)
Let's apply our model to make see if our predictions make sens. We will make predictions for user 1 on the 10 items listed above.

[ ]
0s
# user for which we make predictions
userid = 1

# list of items for which we are making predictions for user 1
items = [1,3,6,47,50,70,101,110,151,157]

# predictions
for itemid in items:
    r = svd.predict(userid=userid, itemid=itemid)
    print('prediction for userid={} and itemid={} : {}'.format(userid, itemid, r))
Our prediction error is less than 0.00001

Make recommendations
The recommend function makes recommendations for a given user.

[ ]
0s
userid = 1

# items sorted in decreasing order of predictions for user 1
sorted_items, preds = svd.recommend(userid=userid)

##
# Now let's exclud from that sorted list items already purchased by the user
##

# list of items rated by the user
uitems = ratings.loc[ratings.userid == userid].itemid.to_list()

# remove from sorted_items items already in uitems and pick the top 30 ones
# as recommendation list
top30 = np.setdiff1d(sorted_items, uitems, assume_unique=True)[:30]

# get corresponding predictions from the top30 items
top30_idx = list(np.where(sorted_items == idx)[0][0] for idx in top30)
top30_predictions = preds[top30_idx]

# find corresponding movie titles
zipped_top30 = list(zip(top30,top30_predictions))
top30 = pd.DataFrame(zipped_top30, columns=['itemid','predictions'])
List = pd.merge(top30, movies, on='itemid', how='inner')

# show the list
List
The first 30 items have an equivalent rating prediction for the user 1

Improving memory based collaborative filtering
SVD can be applied to improve user and item-based collaborative filtering. Instead of computing similarities between user's or item's ratings, we can represent users and items by their corresponding latent factors extracted from the SVD algorithm.

Matrix Factorization
The Matrix Factorization algorithm is a variant of SVD. Also known as Regularized SVD, it uses the Gradient Descent optimizer to optimize the cost function while training the model.

Go to the Matrix Factorization variant of SVD.

Reference
Daniel Billsus and Michael J. Pazzani (1998). Learning Collaborative Information Filters
Sarwar et al. (2000). Application of Dimensionality Reduction in Recommender System -- A Case Study
Author
Carmel WENGA,
PhD student at Université de la Polynésie Française,
Applied Machine Learning Research Engineer,
ShoppingList, NzhinuSoft.

